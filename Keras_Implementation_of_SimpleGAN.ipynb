{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyzG6d6e7z9A6EKn5ryxzg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunalRoutray/Deep-Learning/blob/main/Keras_Implementation_of_SimpleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IXsAeJfIHn7j"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape,Flatten, Input,Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "latent_dim = 100\n",
        "img_shape = (28, 28, 1)\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "sample_interval = 1000\n",
        ""
      ],
      "metadata": {
        "id": "VjuwKOD2Hrst"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess MNIST data\n",
        "\n",
        "(X_train,_), (_, _) = mnist.load_data()\n",
        "X_train = X_train / 127.5 - 1.0 # Normalize images to [-1, 1]\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ9CGOpnHrwO",
        "outputId": "00afd100-f928-48e5-9066-259599ee2207"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Network\n",
        "\n",
        "def build_generator():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, input_dim=100))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dense(256))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dense(512))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dense(1024))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dense(784, activation='tanh')) # Output image vector\n",
        "\n",
        "  noise = Input(shape=(latent_dim,))\n",
        "  img = model(noise)\n",
        "\n",
        "  return Model(noise, img)\n",
        "\n"
      ],
      "metadata": {
        "id": "FppgazEIHr19"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator Network\n",
        "\n",
        "from tensorflow.keras.layers import Dropout, Flatten\n",
        "\n",
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "  # Change input_dim to 784 to match the flattened image size\n",
        "  model.add(Dense(1024, input_dim=784))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(512))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(256))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(256))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(128))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(1, activation='sigmoid')) # Probability output\n",
        "\n",
        "  # The input to the discriminator should be the flattened image\n",
        "  img = Input(shape=(784,))\n",
        "  validity = model(img)\n",
        "\n",
        "  return Model(img, validity)\n",
        ""
      ],
      "metadata": {
        "id": "W8wC6FY0Hr5n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile discriminator\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer=Adam(0.0002, 0.5),metrics=['accuracy'])\n",
        "\n",
        "# Build generator\n",
        "\n",
        "generator = build_generator()\n",
        "\n",
        "# Combined GAN model (generator --> discriminator)\n",
        "\n",
        "z = Input(shape=(latent_dim,))\n",
        "img = generator(z)\n",
        "# The discriminator expects a flattened image, so no reshape is needed here as the generator already outputs a flattened image of shape 784.\n",
        "discriminator.trainable = False # Freeze discriminator during generator training\n",
        "validity = discriminator(img) # Pass the flattened image directly to the discriminator\n",
        "gan = Model(z, validity)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofOO78QRHr-r",
        "outputId": "d04aa2a5-0bbb-42cb-c30d-72ef96931329"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "\n",
        "def train_gan():\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ---------------------\n",
        "        # Train Discriminator\n",
        "        # ---------------------\n",
        "        # Select random real images\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        real_imgs = X_train[idx]\n",
        "\n",
        "        # Flatten the real images before passing them to the discriminator\n",
        "        real_imgs = real_imgs.reshape(batch_size, 784)\n",
        "\n",
        "        # Generate fake images\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train discriminator\n",
        "        d_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "        # d_loss_real and d_loss_fake are lists: [loss, accuracy]\n",
        "        d_loss = 0.5* np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        # Train Generator\n",
        "        # ---------------------\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        g_loss = gan.train_on_batch(noise, valid) # g_loss is a scalar\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % sample_interval == 0:\n",
        "           # Access d_loss elements correctly and handle scalar g_loss\n",
        "           print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy:{100*d_loss[1]}] [G loss: {g_loss}]\")\n",
        "\n",
        "           sample_images(epoch)\n",
        "\n",
        "# Generate and save sample images\n",
        "def sample_images(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r* c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5* gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            # Reshape the generated image for displaying\n",
        "            axs[i,j].imshow(gen_imgs[cnt].reshape(28, 28), cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(f\"mnist_{epoch}.png\")\n",
        "    plt.close()\n",
        ""
      ],
      "metadata": {
        "id": "Gq1lUtw_IGqx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "train_gan()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idtqyd3IILOX",
        "outputId": "cb3eedef-f240-46a2-ecf4-d48364f9c0b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [D loss: 0.6076034307479858 | D accuracy:64.6484375] [G loss: 0.6737447381019592]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LeyhSsuFILSv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NisUkX55ILWV"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}